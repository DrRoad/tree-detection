{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdal\n",
    "from shapely import geometry\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "import traceback\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from numpy.lib import recfunctions as rfn\n",
    "\n",
    "# import laspy\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ept_reader(polygon_wkt: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        Path to ept directory\n",
    "    :param polygon_wkt : wkt\n",
    "        WKT with clipping polygon\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    points : (Mx3) array\n",
    "        The ept points\n",
    "    \"\"\"\n",
    "    polygon = loads(polygon_wkt)\n",
    "    bbox = polygon.bounds\n",
    "    ept_location: str = '/var/data/entwine/ahn3/ept.json'\n",
    "    ept_location: str = 'http://ngi.geodan.nl/maquette/colorized-points/ahn3_nl/ept-subsets/ept.json'\n",
    "    bounds = f\"([{bbox[0]},{bbox[2]}],[{bbox[1]},{bbox[3]}])\"\n",
    "\n",
    "    pipeline_config = {\n",
    "        \"pipeline\": [\n",
    "            {\n",
    "                \"type\": \"readers.ept\",\n",
    "                \"filename\": ept_location,\n",
    "                \"bounds\": bounds\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.crop\",\n",
    "                \"polygon\": polygon_wkt\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"filters.range\",\n",
    "                    \"limits\":\"NumberOfReturns[3:]\"\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"filters.smrf\"\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"filters.range\",\n",
    "                \"limits\":\"Classification[:1]\"\n",
    "            },\n",
    "\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Currently the filter is not limited by numberofreturns or normalz\n",
    "        pipeline = pdal.Pipeline(json.dumps(pipeline_config))\n",
    "        pipeline.validate()  # check if our JSON and options were good\n",
    "        pipeline.execute()\n",
    "    except Exception as e:\n",
    "        trace = traceback.format_exc()\n",
    "        print(\"Unexpected error:\", trace)\n",
    "        print('Polygon:', polygon_wkt)\n",
    "        print(\"Error:\", e)\n",
    "        raise\n",
    "    \n",
    "    arrays = pipeline.arrays\n",
    "    points = arrays[0]\n",
    "    return points\n",
    "\n",
    "\n",
    "def write_to_laz(point_cloud, path):\n",
    "    '''\n",
    "    writes a structured array to a .laz file\n",
    "    in:\n",
    "        point_cloud [structured np array]:\n",
    "            The output pointcloud; needs attributes x, y and z. \n",
    "            When createing a pointcloud from scratch, pay attention to \n",
    "            the data types of the specific attributes, this is a pain in the ass.\n",
    "            Easier to add one new collumn to an existing (filtered) pointcloud.\n",
    "        path [string]:\n",
    "            Path to a laz file.\n",
    "    out:\n",
    "        None\n",
    "    '''\n",
    "    WRITE_PIPELINE = \"\"\"\n",
    "    {{\n",
    "        \"pipeline\": [\n",
    "            {{\n",
    "                \"type\": \"writers.las\",\n",
    "                \"filename\": \"{path}\",\n",
    "                \"extra_dims\": \"all\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    pipeline = pdal.Pipeline(\n",
    "        WRITE_PIPELINE.format(path=path),\n",
    "        arrays=[point_cloud]\n",
    "    )\n",
    "    pipeline.validate()\n",
    "    pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((122668.2 490344.5, 122668.2 490373.4, 122619.6 490373.4, 122619.6 490344.5, 122668.2 490344.5))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# seperate trees\n",
    "# minx, miny, maxx, maxy = 122826.8, 490054.2, 122944.5, 490134.3\n",
    "\n",
    "# separate and dense\n",
    "# minx, miny, maxx, maxy = 122504.4,490066.9, 122665.8,490160.5\n",
    "\n",
    "minx, miny, maxx, maxy = 122619.6,490344.5, 122668.2,490373.4\n",
    "\n",
    "\n",
    "wkt_box = geometry.box(minx, miny, maxx, maxy).wkt\n",
    "print(wkt_box)\n",
    "\n",
    "pts = ept_reader(wkt_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pts = pd.DataFrame(pts[['X','Y','Z','Red','Green','Blue','Intensity','ReturnNumber']])\n",
    "\n",
    "data = f_pts.drop(['X','Y','Z'], axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "st_data = pd.DataFrame(scaler.transform(data), columns = data.columns)\n",
    "\n",
    "st_data = f_pts[['X','Y','Z']].join(st_data)\n",
    "st_data['pid'] = st_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first cluster on XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([st_data.X, st_data.Y]).T\n",
    "xy_clusterer = HDBSCAN(min_cluster_size=40, \n",
    "                        min_samples = 60)\n",
    "xy_clusterer.fit(xy)\n",
    "st_data['xy_clusterID'] = xy_clusterer.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second cluster on color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans,MeanShift\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "sil = []\n",
    "kmax = 10\n",
    "\n",
    "def kmean_cluster(min_clusts, max_clusts, data):\n",
    "    opt_k = 0\n",
    "    p_score = 0\n",
    "    largest_diff = 0\n",
    "    # dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\n",
    "    for k in range(min_clusts+1, max_clusts+1):\n",
    "        kmeans = KMeans(n_clusters = k).fit(data)\n",
    "        labels = kmeans.labels_\n",
    "        n_score = silhouette_score(data, labels, metric = 'euclidean')\n",
    "        diff = abs(n_score - p_score )\n",
    "        print(diff)\n",
    "        if diff > largest_diff:\n",
    "            largest_diff = diff\n",
    "            opt_k = k\n",
    "        p_score = n_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.520548930347634\n",
      "0.1267680571672996\n",
      "0.039266048139865284\n",
      "0.03228438229167574\n",
      "0.025355096775985464\n",
      "0.021980183437920076\n",
      "0.007384818832738671\n",
      "0.013210815608755477\n",
      "0.007827745277809106\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6778 is out of bounds for axis 0 with size 1258",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-0df49cf2e336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0marr_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msorted_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mst_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_clusterID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_labs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxy_clusterID\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mst_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_clusterID\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6778 is out of bounds for axis 0 with size 1258"
     ]
    }
   ],
   "source": [
    "labs = np.array([])\n",
    "n_ids = np.array([])\n",
    "# for name, group in st_data.groupby('xy_clusterID'):\n",
    "#     if group.shape[0] >= 2000:\n",
    "#         value_clusterer = HDBSCAN(min_cluster_size=40, min_samples = 10)\n",
    "#         value_clusterer.fit(group.loc[:,['X','Y','Z']].T)\n",
    "#         labs = np.append(labs, value_clusterer.labels_)\n",
    "#     else:\n",
    "#         labs = np.append(labs, [1] * group.shape[0])\n",
    "        \n",
    "\n",
    "for name, group in st_data.groupby('xy_clusterID'):\n",
    "    if group.shape[0] >= 3000:\n",
    "        k_labs = kmean_cluster(1,10, group[['X','Y','Z']])\n",
    "        labs = np.append(labs, k_labs)\n",
    "    else:\n",
    "        labs = np.append(labs, [1] * group.shape[0])\n",
    "    n_ids = np.append(n_ids, group.pid)\n",
    "\n",
    "arr_inds = n_ids.argsort()\n",
    "sorted_labs = labs[arr_inds]\n",
    "st_data['value_clusterID'] = sorted_labs\n",
    "mask = np.logical_and(st_data.xy_clusterID >=0 , st_data.value_clusterID >= 0)\n",
    "combi_ids = [\"\".join(row) for row in st_data[['value_clusterID', 'xy_clusterID']].values.astype(str)]\n",
    "st_data['unique_CID'] = pd.factorize(combi_ids)[0]\n",
    "\n",
    "print(f'there are {f_pts.shape[0]} pts in the img')\n",
    "print(f'there are {len(set(st_data.xy_clusterID))} xyclusters')\n",
    "print(f'there are {len(set(st_data.value_clusterID))} value clusters')\n",
    "print(f'there are {len(set(st_data.unique_CID))} unique clusters')\n",
    "print(f'there are {list(mask).count(False)} noise, which is {round(list(mask).count(False)/f_pts.shape[0],2)} procenten')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pts = pts[['X','Y','Z','Red','Green','Blue','Intensity','ReturnNumber']]\n",
    "n_pts = rfn.append_fields(out_pts[mask], 'Classification', st_data[mask]['unique_CID'])\n",
    "write_to_laz(n_pts, 'filtered_pts.laz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pts[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt = 'MULTIPOINT ('\n",
    "for lab in set(lab_pts[\"ClusterID\"]):\n",
    "    tre = n_pts[n_pts['Classification'] == lab]\n",
    "    if tre.shape[0] >= 50:\n",
    "        tre_x = tre['X'].mean()\n",
    "        tre_y = tre['Y'].mean()\n",
    "        wkt += f'{tre_x} {tre_y}, '\n",
    "\n",
    "wkt = wkt[:-2] + ')'\n",
    "print(wkt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>ReturnNumber</th>\n",
       "      <th>xy_clusterID</th>\n",
       "      <th>value_clusterID</th>\n",
       "      <th>unique_CID</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>122622.40</td>\n",
       "      <td>490109.44</td>\n",
       "      <td>14.54</td>\n",
       "      <td>1.434361</td>\n",
       "      <td>1.835011</td>\n",
       "      <td>1.771336</td>\n",
       "      <td>0.209410</td>\n",
       "      <td>-1.200406</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>122616.69</td>\n",
       "      <td>490109.56</td>\n",
       "      <td>12.74</td>\n",
       "      <td>-0.203316</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>0.093105</td>\n",
       "      <td>-0.660342</td>\n",
       "      <td>-1.200406</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>122621.63</td>\n",
       "      <td>490112.55</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1.049025</td>\n",
       "      <td>1.508893</td>\n",
       "      <td>1.491631</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-1.200406</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>122616.95</td>\n",
       "      <td>490108.53</td>\n",
       "      <td>12.70</td>\n",
       "      <td>1.338027</td>\n",
       "      <td>1.726305</td>\n",
       "      <td>1.931168</td>\n",
       "      <td>-0.731342</td>\n",
       "      <td>-1.200406</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>122621.04</td>\n",
       "      <td>490107.77</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.434361</td>\n",
       "      <td>1.726305</td>\n",
       "      <td>1.731378</td>\n",
       "      <td>-0.323091</td>\n",
       "      <td>-0.230601</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127076</td>\n",
       "      <td>122619.01</td>\n",
       "      <td>490112.80</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.824246</td>\n",
       "      <td>1.327717</td>\n",
       "      <td>1.251884</td>\n",
       "      <td>-0.411841</td>\n",
       "      <td>0.739205</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>127076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127078</td>\n",
       "      <td>122617.93</td>\n",
       "      <td>490113.16</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.149908</td>\n",
       "      <td>0.421835</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>-0.323091</td>\n",
       "      <td>-0.230601</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>127078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127079</td>\n",
       "      <td>122617.53</td>\n",
       "      <td>490113.11</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-0.331762</td>\n",
       "      <td>-0.194164</td>\n",
       "      <td>0.093105</td>\n",
       "      <td>0.777412</td>\n",
       "      <td>-1.200406</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>127079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127080</td>\n",
       "      <td>122619.12</td>\n",
       "      <td>490113.32</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.663689</td>\n",
       "      <td>0.929129</td>\n",
       "      <td>1.331799</td>\n",
       "      <td>-0.447342</td>\n",
       "      <td>0.739205</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>127080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127081</td>\n",
       "      <td>122618.75</td>\n",
       "      <td>490113.27</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.310465</td>\n",
       "      <td>0.530541</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>0.546661</td>\n",
       "      <td>0.739205</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>127081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X          Y      Z       Red     Green      Blue  Intensity  \\\n",
       "46      122622.40  490109.44  14.54  1.434361  1.835011  1.771336   0.209410   \n",
       "93      122616.69  490109.56  12.74 -0.203316  0.023247  0.093105  -0.660342   \n",
       "237     122621.63  490112.55  12.08  1.049025  1.508893  1.491631  -0.003590   \n",
       "252     122616.95  490108.53  12.70  1.338027  1.726305  1.931168  -0.731342   \n",
       "253     122621.04  490107.77   2.75  1.434361  1.726305  1.731378  -0.323091   \n",
       "...           ...        ...    ...       ...       ...       ...        ...   \n",
       "127076  122619.01  490112.80   1.09  0.824246  1.327717  1.251884  -0.411841   \n",
       "127078  122617.93  490113.16   4.30  0.149908  0.421835  0.692473  -0.323091   \n",
       "127079  122617.53  490113.11   5.42 -0.331762 -0.194164  0.093105   0.777412   \n",
       "127080  122619.12  490113.32   1.02  0.663689  0.929129  1.331799  -0.447342   \n",
       "127081  122618.75  490113.27   1.04  0.310465  0.530541  0.772389   0.546661   \n",
       "\n",
       "        ReturnNumber  xy_clusterID  value_clusterID  unique_CID     pid  \n",
       "46         -1.200406            15              0.0           9      46  \n",
       "93         -1.200406            15              0.0           9      93  \n",
       "237        -1.200406            15              0.0           9     237  \n",
       "252        -1.200406            15              0.0           9     252  \n",
       "253        -0.230601            15              0.0           9     253  \n",
       "...              ...           ...              ...         ...     ...  \n",
       "127076      0.739205            15              1.0          20  127076  \n",
       "127078     -0.230601            15              1.0          20  127078  \n",
       "127079     -1.200406            15              1.0          20  127079  \n",
       "127080      0.739205            15              1.0          20  127080  \n",
       "127081      0.739205            15              1.0          20  127081  \n",
       "\n",
       "[894 rows x 12 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
